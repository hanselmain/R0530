{
    "collab_server" : "",
    "contents" : "---\ntitle: \"大數據分析方法\"\nauthor: \"曾意儒 Yi-Ju Tseng, 長庚大學資管系\"\ndate: \"May 23, 2016\"\noutput: ioslides_presentation\nsubtitle: \"Machine Learning and Data Mining\"\nhighlighter: highlight.js\n---\n\n#作業相關\n\n## 成績\n已請助教回覆，如果有問題的話可以下課或寫信給我或助教。\n\n## 報告....\n- 抄範例也要記得`改錯字`啊....\n- 抄範例也要記得拿掉`沒用的Code和註解`啊.....\n- 5/30 報告的兩組，如果要畢業典禮前拿到成績，這次的作業要提早交\n\n## 基本的R觀念：`Packages`\nR = `主程式`加上一大堆`Packages`\n\n要用特殊的`功能函數`，有時需要另外安裝`packages`，如果出現找不到『Package名稱』的錯誤，可能就是沒安裝過（或是打錯字）。\n\n安裝Packages範例：\n```{r eval=F}\ninstall.packages(\"ggplot2\") ##有引號\n```\n\n出現找不到『要用的函數名稱』，可能是沒有載入packages（或是打錯字）。\n\n載入Packages範例：\n```{r eval=F}\nlibrary(ggplot2) ##不用引號\n```\n\n\n\n## 基本的R Code: subset 子集\n```{r eval=F}\nData[選Row,選Column]\nData[選Row,]$選Column\n```\n\n選擇方式包括：\n\n1. TRUE or FALSE 向量\n2. index（像是只要單數Row，就填入c(1,3,5,7.....)）\n3. Row names or Column names向量\n\n\n## 基本的R Code: subset 子集\n\n選擇方式包括：\n\n1. TRUE or FALSE 向量\n2. index（像是只要單數Row，就填入c(1,3,5,7.....)）\n3. Row names or Column names向量\n\n```{r eval=F}\nData[c(1:3),c(2:4)] # Data[選Row,選Column], index 向量\nData[Data$Select=\"AA\",]$Score #Data[選Row,]$選Column, T/F 向量\nData[Data$Select=\"AA\",\"Score\"] #Data[選Row,選Column], T/F 向量+Column names\n```\n\n## Markdown vs. R Markdown\n\n開GitHub看就知道差別\n\n- Markdown: 在GitHub上呈現成果\n- R Markdown: 利用R，製造Markdown文件\n\n`R Markdown`不只能用在製造`Markdown`文件，也可以做`Slides`，或是`網頁`）\n\n比如說... https://yijutseng.shinyapps.io/Name/\n\n## 點名神器原始碼\n\n<img src=\"Fig/Names.png\" width=\"600px\">\n\n# ML 複習\n\n## Supervised learning 監督式學習 -1\n- Regression 迴歸\n    - Linear Regression 線性迴歸 `Y~X1+X2`，Y連續\n    - `glm(Y~X1+X2, data=DATA, method='gaussian')`\n    - Logistic Regression 邏輯迴歸 `Y~X1+X2`，Y二元\n    - `glm(Y~X1+X2, data=DATA, method='binomial')`\n    - 若自變項X是類別變項，需要建立`虛擬變項`。`R: 轉成factor`\n\n<img src=\"Fig/LogR.png\" width=\"400px\">\n\n\n## Supervised learning 監督式學習 -2\n- Classification 分類\n    - Support Vector Machines 支持向量機\n    - Decision Trees 決策樹 `rpart(Y~X1+X2, data=DATA)`\n    - Neural Networks 神經網路\n    - K-Nearest Neighbor \n        \n<img src=\"Fig/DT.png\" width=\"400px\">\n\n## Unsupervised learning 非監督式學習\n- Clustering 分群\n    - Hierarchical clustering 階層式分群 `hclust()`\n    - K-means clustering `kmeans()`\n- Association Rules 關聯式規則 `apriori()`, from `arules` package\n            \n<img src=\"Fig/hc.png\" width=\"300px\"><img src=\"Fig/kmeans.gif\" width=\"300px\">\n\n\n## 上課用程式碼\n[Rmd下載](https://github.com/yijutseng/BigDataCGUIM/blob/master/BigData20160523.Rmd)\n\n按Raw，右鍵另存新檔\n\n投影片下載：\n\n[Html下載](https://raw.githubusercontent.com/yijutseng/BigDataCGUIM/master/BigData20160523.html)\n\n按右鍵，另存新檔\n\n\n#Association Rules 關聯式規則\n\n## 什麼是關聯式規則？ \n- 用於從大量數據中挖掘出有價值的數據項之間的相關關係\n- 不考慮項目的次序，而僅考慮其組合\n- `購物籃分析 (Market Basket Analysis)`\n- Apriori演算法是挖掘`布林關聯規則` (Boolean association rules) 頻繁項集的算法\n\n## Apriori演算法\n<img src=\"Fig/apriori.png\" width=\"700px\">\n\n## 超市資料分析：讀取資料\n\n```{r warning=F,message=F,fig.height=4.5}\n# Load the libraries\nif (!require('arules')){\n    install.packages(\"arules\");library(arules) #for Apriori演算法\n}\nif (!require('datasets')){\n    install.packages(\"datasets\");library(datasets) #for Groceries data\n}\ndata(Groceries) # Load the data set\nGroceries@data@Dim #169 種商品，9835筆交易資料\n```\n\n## 超市資料長這樣\n<img src=\"Fig/groceries.png\" width=\"700px\">\n\n\n## 超市資料分析：關聯式分析`apriori()`\n\n```{r warning=F,message=F,fig.height=4.5}\n# Get the rules\nrules <- apriori(Groceries, # data= Groceries\n                 parameter = list(supp = 0.001, conf = 0.8), #參數最低限度\n                 control = list(verbose=F)) #不要顯示output\noptions(digits=2) # Only 2 digits\ninspect(rules[1:5]) # Show the top 5 rules\n```\n\n\n## 如何解讀模型\n啤酒=>尿布\n\n- `Support`: 一次交易中，包括規則內的物品的機率。買啤酒同時買尿布的機率。交集\n- `Confidence`: 包含左邊物品A的交易也會包含右邊物品B的條件機率。在買了啤酒的顧客中，有買尿布的比例。\n- `Lift`: 規則的信心比期望值高多少。（買了啤酒以後，有買尿布的機率）/（在所有顧客群中買尿布的機率）\n    - `lift`=1: items on the left and right are independent.\n    \n<img src=\"Fig/support.png\" width=\"700px\">\n\n<img src=\"Fig/conf.png\" width=\"250px\">\n\n<img src=\"Fig/lift.png\" width=\"400px\">\n\n## 列出最有關連的幾條規則\n```{r warning=F,message=F,fig.height=4.5}\nrules<-sort(rules, by=\"confidence\", decreasing=TRUE) #按照confidence排序\ninspect(rules[1:5]) # Show the top 5 rules\n```\n\n## 特別針對某項商品，右邊\n買了什麼東西的人，會買`牛奶`呢？\n```{r warning=F,message=F,fig.height=4.5}\nrulesR<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.08), \n        appearance = list(default=\"lhs\",rhs=\"whole milk\"), #設定右邊一定要是牛奶\n        control = list(verbose=F)) #不要顯示output\nrulesR<-sort(rulesR, decreasing=TRUE,by=\"confidence\") #按照confidence排序\ninspect(rulesR[1:5]) # Show the top 5 rules\n```\n\n## 特別針對某項商品，左邊\n買了`牛奶`的人，會買什麼呢？\n```{r warning=F,message=F,fig.height=4.5}\nrulesL<-apriori(data=Groceries, parameter=list(supp=0.001,conf = 0.15,minlen=2), \n        appearance = list(default=\"rhs\",lhs=\"whole milk\"), #設定左邊一定要是牛奶\n        control = list(verbose=F)) #不要顯示output\nrulesL<-sort(rulesL, decreasing=TRUE,by=\"confidence\") #按照confidence排序\ninspect(rulesL[1:5]) # Show the top 5 rules\n```\n\n\n## 規則視覺化\n```{r eval=F,warning=F,message=F,fig.height=4.5}\nif (!require('arulesViz')){\n    install.packages(\"arulesViz\"); library(arulesViz)\n} \n#Mac->http://planspace.org/2013/01/17/fix-r-tcltk-dependency-problem-on-mac/\nplot(rules,method=\"graph\",interactive=TRUE,shading=NA) #會跑一陣子\n```\n\n<img src=\"Fig/arulesViz.png\" width=\"400px\">  <img src=\"Fig/arulesVizBig.png\" width=\"300px\">\n\n## 參考資料\n- 台大資工林軒田教授（田神）：\n    - [Machine Learning Foundations](www.coursera.org/course/ntumlone)\n    - [Machine Learning Techniques](www.coursera.org/course/ntumltwo)\n    \n- [Market Basket Analysis with R](http://www.salemmarafi.com/code/market-basket-analysis-with-r/)\n\n## 模型驗證？！\n- Training set, Development set: 讓演算法`學`到`知識`\n- Test set, Validation set: 驗證`學`的怎麼樣\n- 通常會比例分配\n    - 2/3的資料設為`Training set`\n    - 剩下的1/3做驗證`Test set`\n\n<img src=\"Fig/SupervisedLearning.png\" width=\"400px\">\n\n\n## 把NBA的資料讀入\n```{r message=FALSE,warning=FALSE}\n#讀入SportsAnalytics package\nif (!require('SportsAnalytics')){\n    install.packages(\"SportsAnalytics\")\n    library(SportsAnalytics)\n}\n#擷取2015-2016年球季球員資料\nNBA1516<-fetch_NBAPlayerStatistics(\"15-16\")\nNBA1516<-NBA1516[complete.cases(NBA1516),]\n```\n\n# Regression 迴歸\n\n## 哪個模型比較好？\n```{r warning=F,message=F,fig.height=4.5}\nOneVar<-glm(TotalPoints~TotalMinutesPlayed,data =NBA1516)\nTwoVar<-glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted,\n            data =NBA1516)\nThreeVar<-glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+Position,\n              data =NBA1516)\nc(OneVar$aic,TwoVar$aic,ThreeVar$aic)\n```\n\n## 好！？\n- 以Training set來`選看起來最好的模型`\n- 用Test set來`驗證模型是不是真的很好`\n- 想像.....訓練出來題庫答得好的學生，寫到新題目不一定會寫！？\n\n## 隨機抽樣？\n```{r message=FALSE,warning=FALSE}\nsample(1:10,3) # 從1到10，隨機取三個數字\nsample(1:nrow(NBA1516),nrow(NBA1516)/3) #從第一行到最後一行，隨機取1/3行數\n```\n\n## 把NBA的資料分成Training 和 Test set\n```{r message=FALSE,warning=FALSE}\nNBA1516$Test<-F #新增一個參數紀錄分組\n#隨機取1/3當Test set\nNBA1516[sample(1:nrow(NBA1516),nrow(NBA1516)/3),]$Test<-T \n# Training set : Test set球員數\nc(sum(NBA1516$Test==F),sum(NBA1516$Test==T)) \n```\n\n\n## 訓練一個多變數線性迴歸模型\n```{r warning=F,message=F,fig.height=4.5}\nfit<-glm(TotalPoints~TotalMinutesPlayed+FieldGoalsAttempted+\n             Position+ThreesAttempted+FreeThrowsAttempted,\n              data =NBA1516[NBA1516$Test==F,])\nfit$aic\nsummary(fit)$coefficients\n```\n\n## 逐步選擇模型 stepwise\n後退學習：一開始先將所有參數加到模型裡，再一個一個拿掉\n```{r warning=F,message=F,fig.height=4.5}\nlibrary(MASS)\n##根據AIC，做逐步選擇, 預設倒退學習 direction = \"backward\"\n##trace=FALSE: 不要顯示步驟\nfinalModel_B<-stepAIC(fit,direction = \"backward\",trace=FALSE) \nsummary(finalModel_B)$coefficients\n```\n\n## 逐步選擇模型 stepwise\n往前學習：一開始先做一個沒有參數的模型，再把參數一個一個加進去\n```{r warning=F,message=F,fig.height=4.5}\n##根據AIC，做逐步選擇, 往前學習 direction = \"forward\"\nfinalModel_F<-stepAIC(fit,direction = \"forward\",trace=FALSE) \nsummary(finalModel_F)$coefficients\n```\n\n## 逐步選擇模型 stepwise\n雙向學習：參數加加減減\n```{r warning=F,message=F,fig.height=4.5}\n##根據AIC，做逐步選擇, 雙向學習 direction = \"both\"\nfinalModel_Both<-stepAIC(fit,direction = \"both\",trace=FALSE) \nsummary(finalModel_Both)$coefficients\n```\n\n\n## 用Test set來評估模型好不好\n```{r warning=F,message=F,fig.height=3}\npredictPoint<-predict(finalModel_Both, #Test==T, test data\n                      newdata = NBA1516[NBA1516$Test==T,]) \ncor(x=predictPoint,y=NBA1516[NBA1516$Test==T,]$TotalPoints) #相關係數\nplot(x=predictPoint,y=NBA1516[NBA1516$Test==T,]$TotalPoints) \n```\n\n# Logistic Regression 邏輯迴歸\n\n## 把入學資料分成Training 和 Test set\n注意：當答案有正反兩面時，`Level 1 要放正面答案`-->有病/錄取...\n```{r warning=F,message=F,fig.height=4.5}\nmydata <- read.csv(\"http://www.ats.ucla.edu/stat/data/binary.csv\")\nmydata$admit <- factor(mydata$admit) # 類別變項要轉為factor\nmydata$rank <- factor(mydata$rank) # 類別變項要轉為factor\nmydata$Test<-F #新增一個參數紀錄分組\nmydata[sample(1:nrow(mydata),nrow(mydata)/3),]$Test<-T #隨機取1/3當Test set\nc(sum(mydata$Test==F),sum(mydata$Test==T)) # Training set : Test set學生數\n#修改一下factor的level: 改成Level 1為錄取，2為不錄取-->Level 1 要放正面答案\nmydata$admit<-factor(mydata$admit,levels=c(1,0))\n```\n\n## 逐步選擇最好的模型\n```{r warning=F,message=F,fig.height=4.5}\n# GRE:某考試成績, GPA:在校平均成績, rank:學校聲望\nmylogit <- glm(admit ~ gre + gpa + rank, \n               data = mydata[mydata$Test==F,], family = \"binomial\")\nfinalFit<-stepAIC(mylogit,direction = \"both\",trace=FALSE) # 雙向逐步選擇模型\nsummary(finalFit)\n```\n\n## 來預測一下新學生可不可以錄取\n```{r warning=F,message=F,fig.height=4.5}\nAdmitProb<-predict(finalFit, # 用Training set做的模型\n                   newdata = mydata[mydata$Test==T,], #Test==T, test data\n                   type=\"response\") #結果為每個人被錄取的機率\nhead(AdmitProb)\ntable(AdmitProb<0.5,mydata[mydata$Test==T,]$admit) # row,column\n```\n\n## 當答案是二元時：效能指標\n- Sensitivity 敏感性\n- Specificity 特異性\n- Positive Predictive Value (PPV) 陽性預測值\n- Negative Predictive Value (NPV) 陰性預測值\n\n## 名詞解釋\n<img src=\"Fig/Cond.png\" width=\"600px\">\n\n- TP: 有病且預測也有病\n- TN: 沒病且預測也沒病\n- FP: 沒病但是預測有病\n- FN: 有病但預測沒病\n\n## 當答案是二元時：效能指標公式\n<img src=\"Fig/para.png\" width=\"400px\">\n\n- Sensitivity 敏感性：所有`真的有病`的人，被`預測有病`的比例\n- Specificity 特異性：所有`真的沒病`的人，被`預測沒病`的比例\n- Positive Predictive Value (PPV) 陽性預測值：所有被`預測有病`的人，`真的有病`的比例\n- Negative Predictive Value (NPV) 陰性預測值：所有被`預測沒病`的人，`真的沒病`的比例\n\n## 回想一下剛剛的驗證結果\n```{r warning=F,message=F,fig.height=4.5}\ntable(AdmitProb<0.5,mydata[mydata$Test==T,]$admit) # row,column\n```\n<img src=\"Fig/para.png\" width=\"500px\">\n\n\n## 計算預測效能參數\n```{r warning=F,message=F,fig.height=4.5}\nAdmitProb<-predict(finalFit,\n                   newdata = mydata[mydata$Test==T,], #Test==T, test data\n                   type=\"response\") #結果為每個人『不』被錄取的機率\nAdmitAns<-factor(ifelse(AdmitProb<0.5,1,0),levels=c(1,0))\nstr(AdmitAns)\n```\n\n## 計算預測效能參數\n```{r warning=F,message=F,fig.height=4.5}\nlibrary(caret) # install.packages(\"caret\") #計算參數的packages\nsensitivity(AdmitAns,mydata[mydata$Test==T,]$admit)\nspecificity(AdmitAns,mydata[mydata$Test==T,]$admit)\nposPredValue(AdmitAns,mydata[mydata$Test==T,]$admit)\nnegPredValue(AdmitAns,mydata[mydata$Test==T,]$admit)\n```\n\n\n\n## 作業 7\n- UCI Machine Learning Repository\n- 單號：Pima Indians Diabetes Database [資料來源](https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n- 雙號：Wisconsin Breast Cancer Database [資料來源](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Original))\n- 5/30 11:59pm繳交\n- 5/30 報告的同學，如果要畢業典禮前拿到成績，這次的作業要提早在5/29 (日)繳交\n\n## 資料介紹: 糖尿病資料集\n- Description: Predict the onset of diabetes in female Pima Indians from medical record data.\n    - Type: Binary Classification\n    - Dimensions: 768 instances, 9 attributes\n    - Inputs: Numeric\n    - Output: Categorical, 2 class labels\n    \n\n## 資料介紹: 糖尿病資料集\n1. Number of times pregnant \n2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n3. Diastolic blood pressure (mm Hg) \n4. Triceps skin fold thickness (mm) \n5. 2-Hour serum insulin (mu U/ml) \n6. Body mass index (weight in kg/(height in m)^2) \n7. Diabetes pedigree function \n8. Age (years) \n9. Class variable (0 or 1) \n\n\n## 資料介紹: 糖尿病資料集\n```{r message=F,warning=F}\n#install.packages(\"mlbench\") # 此package內有很多dataset可練習\nlibrary(mlbench)\ndata(PimaIndiansDiabetes)#雙號\nstr(PimaIndiansDiabetes) #diabetes: pos陽性/neg陰性\n```\n\n    \n## 資料介紹: 乳癌資料集\n- Description: Predict whether a cancer is malignant or benign from biopsy details.\n    - Type: Binary Classification\n    - Dimensions: 699 instances, 11 attributes\n    - Inputs: Integer (Nominal)\n    - Output: Categorical, 2 class labels\n\n\n## 資料介紹: 乳癌資料集\n1. Sample code number: id number \n2. Clump Thickness: 1 - 10 皮膚襞厚度\n3. Uniformity of Cell Size: 1 - 10 \n4. Uniformity of Cell Shape: 1 - 10 \n5. Marginal Adhesion: 1 - 10 邊緣粘連\n6. Single Epithelial Cell Size: 1 - 10 \n7. Bare Nuclei: 1 - 10 \n8. Bland Chromatin: 1 - 10 \n9. Normal Nucleoli: 1 - 10 \n10. Mitoses: 1 - 10 有絲分裂\n11. Class: (2 for benign, 4 for malignant)\n\n## 資料介紹: 乳癌資料集\n```{r message=F,warning=F}\n#install.packages(\"mlbench\") # 此package內有很多dataset可練習\nlibrary(mlbench)\ndata(BreastCancer) #單號\nstr(BreastCancer) #Class: benign良性/malignant陰性\n```\n\n# 作業步驟說明\n\n## 步驟1.1: 讀資料，單號\n```{r message=F,warning=F}\n#install.packages(\"mlbench\") # 此package內有很多dataset可練習\nlibrary(mlbench)\ndata(BreastCancer) #單號\nhead(BreastCancer) #Class: benign良性/malignant陰性\n```\n\n\n## 步驟1.1: 讀資料，雙號\n```{r message=F,warning=F}\n#install.packages(\"mlbench\") # 此package內有很多dataset可練習\nlibrary(mlbench)\ndata(PimaIndiansDiabetes) #雙號\nhead(PimaIndiansDiabetes) #diabetes: pos陽性/neg陰性\n```\n\n## 步驟1.2: 資料前處理\n留下沒有缺值的資料，把無關病情的資料拿掉（像是ID）\n```{r message=F,warning=F}\n# 單號\nBreastCancerC<-BreastCancer[complete.cases(BreastCancer), # 選資料完整的row\n                            !names(BreastCancer) %in% c(\"Id\")] #把Id拿掉 \nc(nrow(BreastCancer),nrow(BreastCancerC))\n\nPimaIndiansDiabetesC<- #雙號\n    PimaIndiansDiabetes[complete.cases(PimaIndiansDiabetes),] # 選資料完整的row\nc(nrow(PimaIndiansDiabetes),nrow(PimaIndiansDiabetesC))\n```\n\n\n## 步驟2:分成訓練組與測試組\n該怎麼分可以自己決定，1/3，1/5...都可以\n```{r}\nBreastCancerC$Test<-F #新增一個參數紀錄分組\n#隨機取1/3當Test set\nBreastCancerC[\n    sample(1:nrow(BreastCancerC),nrow(BreastCancerC)/3),\n     ]$Test<-T \n# 看一下 Training set : Test set 病人數\nc(sum(BreastCancerC$Test==F),sum(BreastCancerC$Test==T)) \n```\n\n## 步驟3:訓練模型\n- 注意只能用`訓練組`的資料，`Test`參數==F，忘記可以看前面範例\n\n模型選擇建議：\n\n- 糖尿病資料：回歸？ `glm()`\n    - formula: diabetes~.    『`.`』代表全部參數\n- 乳癌資料：決策樹？ `rpart()` 需要安裝和使用`rpart` package\n    - formula: Class~.\n- 都試試看？--選一個好的？\n\n提示：要預測的結果，是`二元類別變項` （pos/neg, benign/malignant）\n\n## 步驟4:用測試組驗證模型\n計算以下效能指標：\n\n- Sensitivity\n- Specificity\n- Positive Predictive Value (PPV)\n- Negative Predictive Value (NPV)\n\n<img src=\"Fig/para.png\" width=\"400px\">\n\n## 評分標準 1\n- Title：乳癌/糖尿病 預測模型 (`5 pt`)\n- 次標題1：資料前處理 (`20 pt`)\n    - 解釋資料 (`10 pt`) --可參考`資料介紹`\n    - 把資料讀進來 (`5 pt`)\n    - 分成訓練組跟測試組，並紀錄各組人數 (`5 pt`)\n    \n- 次標題2：預測模型建立 (`35 pt`)\n    - 模型建立、挑選、說明 (`20 pt`)\n    - 模型呈現與說明 (`15 pt`)\n    \n## 評分標準 2\n- 次標題3：預測模型驗證，解釋 (`40 pt`) --依效能給分\n    - Sensitivity (`10 pt`) \n    - Specificity (`10 pt`) \n    - Positive Predictive Value (PPV) (`10 pt`) \n    - Negative Predictive Value (NPV) (`10 pt`) \n\n## 作業7範例 - 完整的Rmd & md檔\n範例是用`\"礦石\"`資料，跟作業不同，要參考的話記得要改說明/資料來源....等等等\n\n[Rmd下載](https://github.com/yijutseng/BigDataCGUIM/blob/master/HW7.Rmd)\n\n[md下載](https://github.com/yijutseng/BigDataCGUIM/blob/master/HW7.md)\n\n# Decision Trees 決策樹 \n\n## 阻攻/籃板/三分/助攻/抄截判斷位置-訓練\n```{r warning=F,message=F,fig.height=4.5}\nif (!require('rpart')){\n    install.packages(\"rpart\"); library(rpart)\n}\nDT<-rpart(Position~Blocks+TotalRebounds+ThreesMade+Assists+Steals,\n          data=NBA1516[NBA1516$Test==F,]) #訓練組 Training set\n#控球後衛（PG）、得分後衛（SG）、小前鋒（SF）、大前鋒（PF）和中鋒（C）\nDT\n```\n\n## 阻攻/籃板/三分/助攻/抄截判斷位置-訓練\n預設的`plot()`真的太難用，改用`rpart.plot` package的`prp()`\n```{r warning=F,message=F,fig.height=4.5}\nif (!require('rpart.plot')){\n    install.packages(\"rpart.plot\"); library(rpart.plot)\n}\nprp(DT)\t# 把決策樹畫出來\n```\n\n## 阻攻/籃板/三分/助攻/抄截判斷位置-訓練\n```{r warning=F,message=F,fig.height=5}\nprp(DT)\n```\n\n## 有批球員沒寫守備位置？--預測\n```{r warning=F,message=F,fig.height=5}\nposPred<-predict(DT,newdata= NBA1516[NBA1516$Test==T,]) #Test==T, test data\n# 預設為class probabilities, type = \"prob\"\nhead(posPred)\n```\n\n\n## 有個人沒寫守備位置--對答案\n```{r warning=F,message=F,fig.height=5}\nresult<-cbind(round(posPred,digits = 2),\n              NBA1516[NBA1516$Test==T,]$Name,\n      as.character(NBA1516[NBA1516$Test==T,]$Position))\nhead(result)\n```\n\n\n## 有個人沒寫守備位置--預測-2\n```{r warning=F,message=F,fig.height=5}\nposPredC<-predict(DT,newdata= NBA1516[NBA1516$Test==T,],type = \"class\") \n# type = \"class\" 直接預測類別\nhead(posPredC)\n```\n\n## 有個人沒寫守備位置--對答案-2\n```{r warning=F,message=F,fig.height=5}\nresultC<-cbind(as.character(posPredC),NBA1516[NBA1516$Test==T,]$Name,\n      as.character(NBA1516[NBA1516$Test==T,]$Position))\nhead(resultC)\n```\n\n\n## 模型驗證\n- Training set, Development set: 讓演算法`學`到`知識`\n- Test set, Validation set: 驗證`學`的怎麼樣\n- 通常會比例分配\n    - 2/3的資料設為`Training set`\n    - 剩下的1/3做驗證`Test set`\n\n- 訓練模型時，只能看Training set，用Training set來選一個最好的模型\n- 訓練模型時，不能偷看Test set，才是真正的`驗證`\n\n\n# 一步一步建立預測模型---範例\n\n## 完整的模型建立步驟範例\n- 標題：以聲波撞擊礦石的回聲預測礦石是否為礦物\n- 以Sonar, Mines vs. Rocks為例\n- 不要直接複製貼上，請按照自己被分配到的資料集寫作業～\n\n\n## 步驟1.1:讀資料\n```{r message=F,warning=F}\n#install.packages(\"mlbench\") # 此package內有很多dataset可練習\nlibrary(mlbench)\ndata(Sonar) \nstr(Sonar) #看一下資料型別，有沒有缺值，類別變項是不是factor\n```\n\n## 在建立模型之前...別忘了基本的資料分析\n在這次的作業內不用包含這個部分\n\n`探索性分析 Exploratory data analysis`，看看資料長怎麼樣\n\n要是有一個參數可以完美的把礦物跟石頭分開，那就不用麻煩了...\n\n## 探索性分析 Exploratory data analysis\n```{r warning=F,message=F,fig.height=4}\nlibrary(ggplot2);library(reshape2) #install.packages(c(\"ggplot2\",\"reshape2\"))\nSonar.m<-melt(Sonar,id.vars = c(\"Class\"))\nggplot(Sonar.m)+geom_boxplot(aes(x=Class,y=value))+ \n    facet_wrap(~variable, nrow=5,scales = \"free_y\") #投影片太小了\n```\n\n## 步驟1.2: 資料前處理\n- 缺值？ \n    - 沒有缺值，不需要處理\n- 答案種類？\n    - 類別變項叫`Class`，M: mine礦-->+, R: rock-->-，不需要處理\n- 類別變項的型別是不是factor？\n    - 是，不需要處理\n- 有沒有無關的參數？\n    - 沒有無關的參數，不需要處理\n\n## 步驟2:分成訓練組與測試組\n該怎麼分可以自己決定，1/3，1/5...都可以\n```{r}\nSonar$Test<-F #新增一個參數紀錄分組\n#隨機取1/3當Test set\nSonar[sample(1:nrow(Sonar),nrow(Sonar)/3),]$Test<-T \n# 看一下 Training set : Test set 案例數\nc(sum(Sonar$Test==F),sum(Sonar$Test==T)) \n```\n\n## 步驟3:訓練模型\n- 注意只能用`訓練組`的資料，`Test`參數==F，忘記可以看前面範例\n- 數值自變項X很多，先用迴歸好了～\n- 要解釋一下模型\n```{r warning=F,message=F}\nfit<-glm(Class~., Sonar[Sonar$Test==F,],family=\"binomial\")\nfinalFit<-stepAIC(fit,direction = \"both\",trace = F)\nsummary(finalFit)$coefficients\n```\n\n\n## 步驟4.1:用測試組驗證模型-預測\n\n```{r warning=F,message=F,fig.height=4.5}\nMinePred<-predict(finalFit,newdata = Sonar[Sonar$Test==T,])\nMineAns<-ifelse(MinePred<0.5,\"M\",\"R\") #<0.5: Level 1\nMineAns<-factor(MineAns,levels = c(\"M\",\"R\"))\nMineAns\n```\n\n\n## 步驟4.2:用測試組驗證模型-效能\n\n```{r warning=F,message=F,fig.height=4.5}\nlibrary(caret) # install.packages(\"caret\") #計算參數的packages\nsensitivity(MineAns,Sonar[Sonar$Test==T,]$Class)\nspecificity(MineAns,Sonar[Sonar$Test==T,]$Class)\nposPredValue(MineAns,Sonar[Sonar$Test==T,]$Class)\nnegPredValue(MineAns,Sonar[Sonar$Test==T,]$Class)\n```\n\n## 解釋範例 - 資料說明\n此資料來源為UCI Machine Learning Repository。\n\n記載礦物與石頭接受各個不同角度的聲波撞擊後，接收到的回聲數值，一共有60個參數，代表使用一特別角度的聲波撞擊礦石所得回聲。另外，分類結果為二元分類，包括礦物 (M) 與石頭 (R) 。\n\n\n## 解釋範例 - 模型說明\n使用聲波在不同角度撞擊`礦石`所得到的回聲資料，以邏輯迴歸建立模型預測礦石是否為礦物，經最佳化後，模型使用參數為V1 + V2 + V3 + V4 + V7 + V11 + V12 + V13 + V17 + V18 + V22 + V24 + V25 + V26 + V30 + V31 + V32 + V38 + V39 + V48 + V50 + V52 + V53 + V58 + V59，共25個參數，各參數代表從一特別角度所得的礦石回聲\n\n## 解釋範例 - 預測效能說明\n使用聲波在不同角度撞擊`礦石`所得到的回聲資料，以邏輯迴歸模型預測礦石是否為礦物，可得敏感度97%，特異性89%，陽性預測率89%，陰性預測率97%。\n\n## 作業7範例 - 完整的Rmd & md檔\n範例是用`\"礦石\"`資料，跟作業不同，要參考的話記得要改說明/資料來源....等等等\n\n[Rmd下載](https://github.com/yijutseng/BigDataCGUIM/blob/master/HW7.Rmd)\n\n[md下載](https://github.com/yijutseng/BigDataCGUIM/blob/master/HW7.md)\n\n",
    "created" : 1464597796493.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "799351892",
    "id" : "E3512EC2",
    "lastKnownWriteTime" : 1464597827,
    "last_content_update" : 1464597827264,
    "path" : "C:/Users/CGU/Desktop/R0530/R0530.Rmd",
    "project_path" : "R0530.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}